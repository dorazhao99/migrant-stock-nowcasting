{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_models(X_train, X_test, y_train, y_test):\n",
    "    # random forest\n",
    "    rf_regr = RandomForestRegressor(max_depth=depth, random_state=random, criterion=\"mae\")\n",
    "    rf_regr.fit(X_train, y_train)\n",
    "    y_pred = rf_regr.predict(X_test)\n",
    "    rf_mape = MAPE(y_test, y_pred)\n",
    "    #print('Random Forests MAPE: {0}'.format(rf_mape))\n",
    "    \n",
    "    # adaboost \n",
    "    ada_regr = AdaBoostRegressor(random_state=random)\n",
    "    ada_regr.fit(X_train, y_train)\n",
    "    y_pred = ada_regr.predict(X_test)\n",
    "    ada_mape = MAPE(y_test, y_pred)\n",
    "    #print('AdaBoost MAPE: {0}'.format(MAPE(y_test, y_pred)))\n",
    "    \n",
    "    # xgboost\n",
    "    xg_regr = XGBRegressor(random_state=random)\n",
    "    xg_regr.fit(X_train, y_train)\n",
    "    y_pred = xg_regr.predict(X_test)\n",
    "    xg_mape = MAPE(y_test, y_pred)\n",
    "    #print('XGBoost MAPE: {0}'.format(MAPE(y_test, y_pred)))\n",
    "    \n",
    "    # linear regression\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "    y_pred = lin_reg.predict(X_test)\n",
    "    lin_mape = MAPE(y_test, y_pred)\n",
    "    #print('Linear Regression MAPE: {0}'.format(MAPE(y_test, y_pred)))\n",
    "    \n",
    "    return np.array([rf_mape, ada_mape, xg_mape, lin_mape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_splits(fb_df, variables = []):\n",
    "    total_columns = [col for col in fb_df.columns[2:] if '2019' not in col]\n",
    "    predictors = fb_df[variables].values if variables != []\\\n",
    "        else fb_df[total_columns].values\n",
    "    gt = fb_df['migrant_2019'].values\n",
    "    \n",
    "    high_predictors = predictors[fb_df['development_lvl'] == 1]\n",
    "    high_gt = gt[fb_df['development_lvl'] == 1]\n",
    "    low_predictors = predictors[fb_df['development_lvl'] == 0]\n",
    "    low_gt = gt[fb_df['development_lvl'] == 0]\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    kf_split = kf.split(predictors, gt)\n",
    "    \n",
    "    splits = dict()\n",
    "    # 1. Randomly sample from all countries for training and test sets.\n",
    "    #splits[\"random_all\"] = train_test_split(predictors, gt, test_size=0.2, random_state=42)\n",
    "    splits[\"random_all\"] = [(predictors[i], predictors[j], gt[i], gt[j]) for i, j in kf.split(predictors, gt)]\n",
    "    # 2. Train more developed, test less developed\n",
    "    splits[\"train_high_test_low\"] = [(high_predictors, low_predictors, high_gt, low_gt)]\n",
    "    # 3. Train less developed, test more developed\n",
    "    splits[\"train_low_test_high\"] = [(low_predictors, high_predictors, low_gt, high_gt)]\n",
    "    # 4. Randomly sample high for train+test\n",
    "    #splits[\"train_test_high\"] = train_test_split(high_predictors, high_gt, test_size=0.2, random_state=42)\n",
    "    splits[\"train_test_high\"] = [(high_predictors[i], high_predictors[j], high_gt[i], high_gt[j]) for i, j in kf.split(high_predictors, high_gt)]\n",
    "    # 5. Randomly sample low for train+test\n",
    "    #splits[\"train_test_low\"] = train_test_split(low_predictors, low_gt, test_size=0.2, random_state=42)\n",
    "    splits[\"train_test_low\"] = [(low_predictors[i], low_predictors[j], low_gt[i], low_gt[j]) for i, j in kf.split(low_predictors, low_gt)]\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in UN data\n",
    "un_df = pd.read_csv('../data/UN_data_clean.csv')\n",
    "# ground truth data for all of the models\n",
    "y = np.array((un_df[(un_df['age_group'] == 'Total') & (un_df['sex'] == 'both sexes') & (un_df['year'] == 2019)]\\\n",
    "          ['migrant_pop']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in combined fb_un_data\n",
    "fb_df = pd.read_csv('../data/facebook_un_combined_2019.csv')\n",
    "fb_df_2020 = pd.read_csv('../data/facebook_un_combined_2020.csv')\n",
    "predictors = fb_df.values [:, 2:176]\n",
    "gt = fb_df['migrant_2019'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "depth = 5\n",
    "random = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('model_mapes.csv','w')\n",
    "writer = csv.writer(f, delimiter=',')\n",
    "writer.writerow([\"model\", \"split\", \"rf_mape\", \"adaboost_mape\", \"xgboost_mape\", \"linreg_mape\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Autoregressive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_all: \n",
      "[ 42.02446425 854.60815739  32.44764284  97.60701627]\n",
      "\n",
      "\n",
      "train_high_test_low: \n",
      "[ 187.43006888 1686.81040411   86.74464025  156.33946143]\n",
      "\n",
      "\n",
      "train_low_test_high: \n",
      "[21.11290759 60.2285136  33.14075178 10.59468046]\n",
      "\n",
      "\n",
      "train_test_high: \n",
      "[18.3662049  97.82886392 15.78447345 22.29603912]\n",
      "\n",
      "\n",
      "train_test_low: \n",
      "[ 30.90469672 472.28408286  27.39933143  64.50992431]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splits = gen_splits(fb_df, ['un_expat_total_age16_2017', 'un_expat_total_age16_2015'])\n",
    "\n",
    "for (k, folds) in splits.items():\n",
    "    print(k + \": \")\n",
    "    mapes = np.array([0.]*4)\n",
    "    for fold in folds: \n",
    "        mapes+=run_all_models(*fold)\n",
    "    mapes/=len(folds)\n",
    "    writer.writerow([\"autoregressive_baseline\", k, *mapes])\n",
    "    print(mapes)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_all: \n",
      "[207.95859728 708.25973069 252.20157076 310.93996917]\n",
      "\n",
      "\n",
      "train_high_test_low: \n",
      "[ 611.11685316 1400.85947611  684.74336801 1761.73752735]\n",
      "\n",
      "\n",
      "train_low_test_high: \n",
      "[56.59768649 61.56077997 83.58140511 54.76032061]\n",
      "\n",
      "\n",
      "train_test_high: \n",
      "[ 55.97299008  98.13817427  69.15245206 206.16529846]\n",
      "\n",
      "\n",
      "train_test_low: \n",
      "[264.90621803 623.53828116 342.11459058 322.3538709 ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splits = gen_splits(fb_df, ['total_expat'])\n",
    "\n",
    "for (k, folds) in splits.items():\n",
    "    print(k + \": \")\n",
    "    mapes = np.array([0.]*4)\n",
    "    for fold in folds: \n",
    "        mapes+=run_all_models(*fold)\n",
    "    mapes/=len(folds)\n",
    "    writer.writerow([\"fb_naive\", k, *mapes])\n",
    "    print(mapes)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregressive + Facebook Expats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_all: \n",
      "[ 49.06118056 774.16988565  19.97254989  91.98927695]\n",
      "\n",
      "\n",
      "train_high_test_low: \n",
      "[ 230.39012333 1522.75187341   78.14617697  162.46622932]\n",
      "\n",
      "\n",
      "train_low_test_high: \n",
      "[17.96135422 54.11590006 16.08311878  7.74661822]\n",
      "\n",
      "\n",
      "train_test_high: \n",
      "[ 18.22736018 133.58336877  15.24838657  22.65209668]\n",
      "\n",
      "\n",
      "train_test_low: \n",
      "[ 39.99946132 570.27093344  27.18229063  40.53309467]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splits = gen_splits(fb_df, ['un_expat_total_age16_2017', 'un_expat_total_age16_2015', 'total_expat'])\n",
    "\n",
    "for (k, folds) in splits.items():\n",
    "    print(k + \": \")\n",
    "    mapes = np.array([0.]*4)\n",
    "    for fold in folds: \n",
    "        mapes+=run_all_models(*fold)\n",
    "    mapes/=len(folds)\n",
    "    writer.writerow([\"autoregressive_plus_fb\", k, *mapes])\n",
    "    print(mapes)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook age-sex corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_all: \n",
      "[ 218.99879811 2648.21488505  216.19787864  498.55632602]\n",
      "\n",
      "\n",
      "train_high_test_low: \n",
      "[1394.32611047 3225.34415569 1927.20981416 3055.61785047]\n",
      "\n",
      "\n",
      "train_low_test_high: \n",
      "[50.53611554 72.06935688 80.6463588  66.68132532]\n",
      "\n",
      "\n",
      "train_test_high: \n",
      "[ 48.0154907  129.25741736  49.50113586 280.8595249 ]\n",
      "\n",
      "\n",
      "train_test_low: \n",
      "[285.64083237 742.97575176 233.89595711 658.06482297]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "norm_columns = [col for col in fb_df.columns if 'normalized' in col]\n",
    "splits = gen_splits(fb_df, norm_columns)\n",
    "\n",
    "for (k, folds) in splits.items():\n",
    "    print(k + \": \")\n",
    "    mapes = np.array([0.]*4)\n",
    "    for fold in folds: \n",
    "        mapes+=run_all_models(*fold)\n",
    "    mapes/=len(folds)\n",
    "    writer.writerow([\"fb_age_sex_normalized\", k, *mapes])\n",
    "    print(mapes)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook age-sex corrected (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_all: \n",
      "[ 217.30635944 1707.73629931  230.12950369  431.72965451]\n",
      "\n",
      "\n",
      "train_high_test_low: \n",
      "[1418.03008617 3224.06931642 1854.14464967 3444.96737348]\n",
      "\n",
      "\n",
      "train_low_test_high: \n",
      "[50.92767942 90.93367548 83.83098209 66.96094387]\n",
      "\n",
      "\n",
      "train_test_high: \n",
      "[ 48.7604281  139.072057    51.61337101 227.43864852]\n",
      "\n",
      "\n",
      "train_test_low: \n",
      "[292.34746673 712.38578059 276.44610001 720.85965534]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "norm_columns = [col for col in fb_df_2020.columns if 'normalized' in col]\n",
    "splits = gen_splits(fb_df_2020, norm_columns)\n",
    "\n",
    "for (k, folds) in splits.items():\n",
    "    print(k + \": \")\n",
    "    mapes = np.array([0.]*4)\n",
    "    for fold in folds: \n",
    "        mapes+=run_all_models(*fold)\n",
    "    mapes/=len(folds)\n",
    "    writer.writerow([\"fb_age_sex_normalized_2020\", k, *mapes])\n",
    "    print(mapes)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook age-sex corrected with autoregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_all: \n",
      "[  48.39706425 1070.91661223   31.76776737   59.34510741]\n",
      "\n",
      "\n",
      "train_high_test_low: \n",
      "[ 819.14498681 1695.50697602 1498.60469292 1185.74316316]\n",
      "\n",
      "\n",
      "train_low_test_high: \n",
      "[13.40422618 85.97478079 13.61356441 14.65745128]\n",
      "\n",
      "\n",
      "train_test_high: \n",
      "[ 35.1268161  157.46835003  31.98382651  39.04414446]\n",
      "\n",
      "\n",
      "train_test_low: \n",
      "[ 40.95339784 662.44981791  35.35438634 173.44526699]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "norm_columns = [col for col in fb_df.columns if 'normalized' in col]\n",
    "norm_columns.extend(['un_expat_total_age16_2017', 'un_expat_total_age16_2015'])\n",
    "splits = gen_splits(fb_df, norm_columns)\n",
    "\n",
    "for (k, folds) in splits.items():\n",
    "    print(k + \": \")\n",
    "    mapes = np.array([0.]*4)\n",
    "    for fold in folds: \n",
    "        mapes+=run_all_models(*fold)\n",
    "    mapes/=len(folds)\n",
    "    writer.writerow([\"autoregressive_with_fb_normalized\", k, *mapes])\n",
    "    print(mapes)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook age-sex corrected with autoregression (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_all: \n",
      "[ 48.69446258 991.07552476  29.99699642  54.84774068]\n",
      "\n",
      "\n",
      "train_high_test_low: \n",
      "[ 852.38650511 1991.22431395 1518.66333758  921.71990486]\n",
      "\n",
      "\n",
      "train_low_test_high: \n",
      "[13.50376307 63.05374468 15.4051986  13.4105808 ]\n",
      "\n",
      "\n",
      "train_test_high: \n",
      "[ 36.01973524 161.13485698  35.47912186  37.01272483]\n",
      "\n",
      "\n",
      "train_test_low: \n",
      "[ 40.99730236 580.97283807  36.67364529 193.87170796]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "norm_columns = [col for col in fb_df_2020.columns if 'normalized' in col]\n",
    "norm_columns.extend(['un_expat_total_age16_2017', 'un_expat_total_age16_2015'])\n",
    "splits = gen_splits(fb_df_2020, norm_columns)\n",
    "\n",
    "for (k, folds) in splits.items():\n",
    "    print(k + \": \")\n",
    "    mapes = np.array([0.]*4)\n",
    "    for fold in folds: \n",
    "        mapes+=run_all_models(*fold)\n",
    "    mapes/=len(folds)\n",
    "    writer.writerow([\"autoregressive_with_fb_normalized_2020\", k, *mapes])\n",
    "    print(mapes)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Predictors (2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_all: \n",
      "[ 47.77605527 924.44773694  26.65698106 246.53271424]\n",
      "\n",
      "\n",
      "train_high_test_low: \n",
      "[ 493.38596882 1239.38893074  718.57208496  161.13382044]\n",
      "\n",
      "\n",
      "train_low_test_high: \n",
      "[21.56126208 76.77237524 16.39759357 68.19708567]\n",
      "\n",
      "\n",
      "train_test_high: \n",
      "[ 27.37924137 142.63685787  35.41667761  18.85839753]\n",
      "\n",
      "\n",
      "train_test_low: \n",
      "[ 39.47129843 642.37249416  37.29538285 117.72098743]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splits = gen_splits(fb_df)\n",
    "\n",
    "for (k, folds) in splits.items():\n",
    "    print(k + \": \")\n",
    "    mapes = np.array([0.]*4)\n",
    "    for fold in folds: \n",
    "        mapes+=run_all_models(*fold)\n",
    "    mapes/=len(folds)\n",
    "    writer.writerow([\"all_preds\", k, *mapes])\n",
    "    print(mapes)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
